{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Word2Vec with Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec is an approach to learning *word embeddings*, vector representations of words that capture semantic and syntactic relationships between words based on their co-occurrences in natural language text. \n",
    "\n",
    "This unsupervised learning approach also reduces the dimensionality of the vectors representing words, which can be helpful for memory and to manage the *curse of dimensionality*, whereby high-dimensional vector spaces lead to a relative data sparsity, e.g., for machine learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will look at the capabilities of Word2Vec as implemented in the module Gensim. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the lines below, run the installations once as needed, then comment the code out again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade pip\n",
    "#!pip install --upgrade Cython\n",
    "#!pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all necessary libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules and set up logging.\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "import ipytest\n",
    "import pytest\n",
    "\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_records': 1701, 'record_format': 'list of str (tokens)', 'file_size': 33182058, 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/text8/__init__.py', 'license': 'not found', 'description': 'First 100,000,000 bytes of plain text from Wikipedia. Used for testing purposes; see wiki-english-* for proper full Wikipedia datasets.', 'checksum': '68799af40b6bda07dfa47a32612e5364', 'file_name': 'text8.gz', 'read_more': ['http://mattmahoney.net/dc/textdata.html'], 'parts': 1}\n"
     ]
    }
   ],
   "source": [
    "# Load the Text8 corpus.\n",
    "print(api.info('text8'))\n",
    "text8_corpus = api.load('text8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-12 12:53:17,379 : INFO : collecting all words and their counts\n",
      "2020-10-12 12:53:17,390 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-10-12 12:53:23,698 : INFO : collected 253854 word types from a corpus of 17005207 raw words and 1701 sentences\n",
      "2020-10-12 12:53:23,699 : INFO : Loading a fresh vocabulary\n",
      "2020-10-12 12:53:23,983 : INFO : effective_min_count=5 retains 71290 unique words (28% of original 253854, drops 182564)\n",
      "2020-10-12 12:53:23,983 : INFO : effective_min_count=5 leaves 16718844 word corpus (98% of original 17005207, drops 286363)\n",
      "2020-10-12 12:53:24,201 : INFO : deleting the raw counts dictionary of 253854 items\n",
      "2020-10-12 12:53:24,215 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-10-12 12:53:24,216 : INFO : downsampling leaves estimated 12506280 word corpus (74.8% of prior 16718844)\n",
      "2020-10-12 12:53:24,487 : INFO : estimated required memory for 71290 words and 100 dimensions: 92677000 bytes\n",
      "2020-10-12 12:53:24,487 : INFO : resetting layer weights\n",
      "2020-10-12 12:53:40,336 : INFO : training model with 3 workers on 71290 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-10-12 12:53:41,369 : INFO : EPOCH 1 - PROGRESS: at 5.06% examples, 613039 words/s, in_qsize 4, out_qsize 1\n",
      "2020-10-12 12:53:42,370 : INFO : EPOCH 1 - PROGRESS: at 10.11% examples, 617445 words/s, in_qsize 4, out_qsize 0\n",
      "2020-10-12 12:53:43,370 : INFO : EPOCH 1 - PROGRESS: at 15.11% examples, 618977 words/s, in_qsize 6, out_qsize 0\n",
      "2020-10-12 12:53:44,376 : INFO : EPOCH 1 - PROGRESS: at 19.52% examples, 601360 words/s, in_qsize 5, out_qsize 0\n",
      "2020-10-12 12:53:45,377 : INFO : EPOCH 1 - PROGRESS: at 23.75% examples, 587897 words/s, in_qsize 1, out_qsize 0\n",
      "2020-10-12 12:53:46,387 : INFO : EPOCH 1 - PROGRESS: at 27.81% examples, 574326 words/s, in_qsize 5, out_qsize 0\n",
      "2020-10-12 12:53:47,401 : INFO : EPOCH 1 - PROGRESS: at 32.57% examples, 577240 words/s, in_qsize 5, out_qsize 0\n",
      "2020-10-12 12:53:48,405 : INFO : EPOCH 1 - PROGRESS: at 37.86% examples, 588132 words/s, in_qsize 2, out_qsize 0\n",
      "2020-10-12 12:53:49,432 : INFO : EPOCH 1 - PROGRESS: at 42.56% examples, 586568 words/s, in_qsize 4, out_qsize 1\n",
      "2020-10-12 12:53:50,441 : INFO : EPOCH 1 - PROGRESS: at 46.97% examples, 582813 words/s, in_qsize 5, out_qsize 0\n",
      "2020-10-12 12:53:51,455 : INFO : EPOCH 1 - PROGRESS: at 52.03% examples, 586662 words/s, in_qsize 5, out_qsize 0\n",
      "2020-10-12 12:53:52,456 : INFO : EPOCH 1 - PROGRESS: at 57.14% examples, 591381 words/s, in_qsize 5, out_qsize 0\n",
      "2020-10-12 12:53:53,458 : INFO : EPOCH 1 - PROGRESS: at 62.32% examples, 595679 words/s, in_qsize 2, out_qsize 1\n",
      "2020-10-12 12:53:54,482 : INFO : EPOCH 1 - PROGRESS: at 67.61% examples, 599427 words/s, in_qsize 3, out_qsize 1\n",
      "2020-10-12 12:53:55,487 : INFO : EPOCH 1 - PROGRESS: at 72.96% examples, 604085 words/s, in_qsize 4, out_qsize 0\n",
      "2020-10-12 12:53:56,498 : INFO : EPOCH 1 - PROGRESS: at 78.37% examples, 607154 words/s, in_qsize 3, out_qsize 0\n",
      "2020-10-12 12:53:57,510 : INFO : EPOCH 1 - PROGRESS: at 83.48% examples, 608509 words/s, in_qsize 5, out_qsize 0\n",
      "2020-10-12 12:53:58,520 : INFO : EPOCH 1 - PROGRESS: at 88.65% examples, 610333 words/s, in_qsize 4, out_qsize 1\n",
      "2020-10-12 12:53:59,523 : INFO : EPOCH 1 - PROGRESS: at 93.83% examples, 611881 words/s, in_qsize 5, out_qsize 0\n",
      "2020-10-12 12:54:00,549 : INFO : EPOCH 1 - PROGRESS: at 98.71% examples, 610863 words/s, in_qsize 5, out_qsize 1\n",
      "2020-10-12 12:54:00,759 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-12 12:54:00,764 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-12 12:54:00,771 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-12 12:54:00,771 : INFO : EPOCH - 1 : training on 17005207 raw words (12506677 effective words) took 20.4s, 612077 effective words/s\n",
      "2020-10-12 12:54:01,792 : INFO : EPOCH 2 - PROGRESS: at 4.88% examples, 599435 words/s, in_qsize 6, out_qsize 0\n",
      "2020-10-12 12:54:02,812 : INFO : EPOCH 2 - PROGRESS: at 8.58% examples, 523110 words/s, in_qsize 6, out_qsize 0\n",
      "2020-10-12 12:54:03,839 : INFO : EPOCH 2 - PROGRESS: at 13.93% examples, 565200 words/s, in_qsize 4, out_qsize 1\n",
      "2020-10-12 12:54:04,849 : INFO : EPOCH 2 - PROGRESS: at 19.17% examples, 585248 words/s, in_qsize 4, out_qsize 0\n",
      "2020-10-12 12:54:05,865 : INFO : EPOCH 2 - PROGRESS: at 24.40% examples, 597887 words/s, in_qsize 6, out_qsize 0\n",
      "2020-10-12 12:54:06,871 : INFO : EPOCH 2 - PROGRESS: at 29.69% examples, 609182 words/s, in_qsize 5, out_qsize 0\n",
      "2020-10-12 12:54:07,874 : INFO : EPOCH 2 - PROGRESS: at 34.80% examples, 614234 words/s, in_qsize 4, out_qsize 1\n",
      "2020-10-12 12:54:08,891 : INFO : EPOCH 2 - PROGRESS: at 40.09% examples, 619119 words/s, in_qsize 5, out_qsize 0\n",
      "2020-10-12 12:54:09,896 : INFO : EPOCH 2 - PROGRESS: at 44.68% examples, 614022 words/s, in_qsize 4, out_qsize 1\n",
      "2020-10-12 12:54:10,907 : INFO : EPOCH 2 - PROGRESS: at 48.38% examples, 598649 words/s, in_qsize 5, out_qsize 0\n",
      "2020-10-12 12:54:11,922 : INFO : EPOCH 2 - PROGRESS: at 53.91% examples, 606497 words/s, in_qsize 3, out_qsize 0\n",
      "2020-10-12 12:54:12,942 : INFO : EPOCH 2 - PROGRESS: at 59.73% examples, 615731 words/s, in_qsize 0, out_qsize 2\n",
      "2020-10-12 12:54:13,944 : INFO : EPOCH 2 - PROGRESS: at 66.02% examples, 628696 words/s, in_qsize 5, out_qsize 0\n",
      "2020-10-12 12:54:14,953 : INFO : EPOCH 2 - PROGRESS: at 72.37% examples, 640277 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 12:54:15,961 : INFO : EPOCH 2 - PROGRESS: at 78.66% examples, 648611 words/s, in_qsize 2, out_qsize 0\n",
      "2020-10-12 12:54:16,969 : INFO : EPOCH 2 - PROGRESS: at 84.89% examples, 656166 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 12:54:17,970 : INFO : EPOCH 2 - PROGRESS: at 91.18% examples, 663715 words/s, in_qsize 5, out_qsize 0\n",
      "2020-10-12 12:54:18,974 : INFO : EPOCH 2 - PROGRESS: at 97.47% examples, 670011 words/s, in_qsize 5, out_qsize 0\n",
      "2020-10-12 12:54:19,339 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-12 12:54:19,341 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-12 12:54:19,347 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-12 12:54:19,348 : INFO : EPOCH - 2 : training on 17005207 raw words (12507422 effective words) took 18.6s, 673423 effective words/s\n",
      "2020-10-12 12:54:20,358 : INFO : EPOCH 3 - PROGRESS: at 6.47% examples, 796760 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 12:54:21,359 : INFO : EPOCH 3 - PROGRESS: at 12.58% examples, 777659 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 12:54:22,363 : INFO : EPOCH 3 - PROGRESS: at 18.34% examples, 757909 words/s, in_qsize 0, out_qsize 1\n",
      "2020-10-12 12:54:23,366 : INFO : EPOCH 3 - PROGRESS: at 24.16% examples, 750967 words/s, in_qsize 4, out_qsize 1\n",
      "2020-10-12 12:54:24,372 : INFO : EPOCH 3 - PROGRESS: at 30.22% examples, 752936 words/s, in_qsize 4, out_qsize 0\n",
      "2020-10-12 12:54:25,378 : INFO : EPOCH 3 - PROGRESS: at 36.68% examples, 762827 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 12:54:26,381 : INFO : EPOCH 3 - PROGRESS: at 43.15% examples, 769481 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 12:54:27,381 : INFO : EPOCH 3 - PROGRESS: at 49.62% examples, 774730 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 12:54:28,385 : INFO : EPOCH 3 - PROGRESS: at 56.20% examples, 780421 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 12:54:29,388 : INFO : EPOCH 3 - PROGRESS: at 61.61% examples, 769860 words/s, in_qsize 3, out_qsize 1\n",
      "2020-10-12 12:54:30,389 : INFO : EPOCH 3 - PROGRESS: at 67.78% examples, 770043 words/s, in_qsize 5, out_qsize 0\n",
      "2020-10-12 12:54:31,399 : INFO : EPOCH 3 - PROGRESS: at 73.96% examples, 769978 words/s, in_qsize 4, out_qsize 0\n",
      "2020-10-12 12:54:32,403 : INFO : EPOCH 3 - PROGRESS: at 80.48% examples, 771848 words/s, in_qsize 2, out_qsize 0\n",
      "2020-10-12 12:54:33,409 : INFO : EPOCH 3 - PROGRESS: at 87.24% examples, 776598 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 12:54:34,417 : INFO : EPOCH 3 - PROGRESS: at 93.89% examples, 779535 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 12:54:35,327 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-12 12:54:35,336 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-12 12:54:35,339 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-12 12:54:35,339 : INFO : EPOCH - 3 : training on 17005207 raw words (12505275 effective words) took 16.0s, 782139 effective words/s\n",
      "2020-10-12 12:54:36,347 : INFO : EPOCH 4 - PROGRESS: at 6.58% examples, 813035 words/s, in_qsize 2, out_qsize 0\n",
      "2020-10-12 12:54:37,368 : INFO : EPOCH 4 - PROGRESS: at 13.11% examples, 804042 words/s, in_qsize 0, out_qsize 1\n",
      "2020-10-12 12:54:38,373 : INFO : EPOCH 4 - PROGRESS: at 18.75% examples, 770362 words/s, in_qsize 5, out_qsize 0\n",
      "2020-10-12 12:54:39,377 : INFO : EPOCH 4 - PROGRESS: at 25.10% examples, 776023 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 12:54:40,380 : INFO : EPOCH 4 - PROGRESS: at 31.63% examples, 785945 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 12:54:41,385 : INFO : EPOCH 4 - PROGRESS: at 38.10% examples, 790426 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 12:54:42,393 : INFO : EPOCH 4 - PROGRESS: at 44.33% examples, 788064 words/s, in_qsize 1, out_qsize 0\n",
      "2020-10-12 12:54:43,405 : INFO : EPOCH 4 - PROGRESS: at 50.56% examples, 786433 words/s, in_qsize 5, out_qsize 0\n",
      "2020-10-12 12:54:44,412 : INFO : EPOCH 4 - PROGRESS: at 57.03% examples, 788634 words/s, in_qsize 3, out_qsize 0\n",
      "2020-10-12 12:54:45,418 : INFO : EPOCH 4 - PROGRESS: at 63.55% examples, 791175 words/s, in_qsize 4, out_qsize 1\n",
      "2020-10-12 12:54:46,423 : INFO : EPOCH 4 - PROGRESS: at 69.84% examples, 790501 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 12:54:47,426 : INFO : EPOCH 4 - PROGRESS: at 75.78% examples, 785829 words/s, in_qsize 2, out_qsize 1\n",
      "2020-10-12 12:54:48,438 : INFO : EPOCH 4 - PROGRESS: at 82.07% examples, 784417 words/s, in_qsize 5, out_qsize 0\n",
      "2020-10-12 12:54:49,443 : INFO : EPOCH 4 - PROGRESS: at 88.42% examples, 784873 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 12:54:50,445 : INFO : EPOCH 4 - PROGRESS: at 94.65% examples, 784128 words/s, in_qsize 1, out_qsize 0\n",
      "2020-10-12 12:54:51,260 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-12 12:54:51,271 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-12 12:54:51,282 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-12 12:54:51,283 : INFO : EPOCH - 4 : training on 17005207 raw words (12507434 effective words) took 15.9s, 784609 effective words/s\n",
      "2020-10-12 12:54:52,290 : INFO : EPOCH 5 - PROGRESS: at 6.11% examples, 757072 words/s, in_qsize 1, out_qsize 0\n",
      "2020-10-12 12:54:53,293 : INFO : EPOCH 5 - PROGRESS: at 12.05% examples, 745480 words/s, in_qsize 4, out_qsize 0\n",
      "2020-10-12 12:54:54,296 : INFO : EPOCH 5 - PROGRESS: at 18.52% examples, 765539 words/s, in_qsize 2, out_qsize 0\n",
      "2020-10-12 12:54:55,299 : INFO : EPOCH 5 - PROGRESS: at 24.93% examples, 774689 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 12:54:56,313 : INFO : EPOCH 5 - PROGRESS: at 31.10% examples, 774168 words/s, in_qsize 5, out_qsize 0\n",
      "2020-10-12 12:54:57,327 : INFO : EPOCH 5 - PROGRESS: at 37.33% examples, 774553 words/s, in_qsize 5, out_qsize 0\n",
      "2020-10-12 12:54:58,339 : INFO : EPOCH 5 - PROGRESS: at 43.39% examples, 771104 words/s, in_qsize 4, out_qsize 0\n",
      "2020-10-12 12:54:59,344 : INFO : EPOCH 5 - PROGRESS: at 49.74% examples, 773916 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 12:55:00,370 : INFO : EPOCH 5 - PROGRESS: at 55.79% examples, 770455 words/s, in_qsize 4, out_qsize 1\n",
      "2020-10-12 12:55:01,392 : INFO : EPOCH 5 - PROGRESS: at 62.49% examples, 775614 words/s, in_qsize 5, out_qsize 0\n",
      "2020-10-12 12:55:02,396 : INFO : EPOCH 5 - PROGRESS: at 69.02% examples, 779203 words/s, in_qsize 5, out_qsize 0\n",
      "2020-10-12 12:55:03,405 : INFO : EPOCH 5 - PROGRESS: at 75.60% examples, 781753 words/s, in_qsize 4, out_qsize 0\n",
      "2020-10-12 12:55:04,422 : INFO : EPOCH 5 - PROGRESS: at 82.13% examples, 782501 words/s, in_qsize 6, out_qsize 0\n",
      "2020-10-12 12:55:05,434 : INFO : EPOCH 5 - PROGRESS: at 88.59% examples, 783722 words/s, in_qsize 4, out_qsize 0\n",
      "2020-10-12 12:55:06,435 : INFO : EPOCH 5 - PROGRESS: at 94.94% examples, 784133 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 12:55:07,232 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-12 12:55:07,237 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-12 12:55:07,238 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-12 12:55:07,239 : INFO : EPOCH - 5 : training on 17005207 raw words (12506302 effective words) took 16.0s, 783935 effective words/s\n",
      "2020-10-12 12:55:07,240 : INFO : training on a 85026035 raw words (62533110 effective words) took 86.9s, 719588 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6936887\n"
     ]
    }
   ],
   "source": [
    "# Train a Word2Vec model on the Text8 corpus with default hyperparameters. \n",
    "model = Word2Vec(text8_corpus)  \n",
    "\n",
    "# Perform a sanity check on the trained model.\n",
    "print(model.wv.similarity('tree', 'leaf')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce logging level.\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-12 12:55:07,262 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('leaf', 0.6936887502670288), ('trees', 0.6819906234741211), ('bark', 0.6473582983016968), ('flower', 0.6167069673538208), ('cactus', 0.611079216003418), ('avl', 0.6076448559761047), ('fruit', 0.605135440826416), ('bird', 0.6035254001617432), ('vine', 0.5807324647903442), ('cave', 0.5720144510269165)]\n",
      "[('flower', 0.7811040878295898), ('coloured', 0.7625181674957275), ('colored', 0.7616524696350098), ('grass', 0.7488452196121216), ('bark', 0.7405838966369629), ('haliotis', 0.7371957898139954), ('goat', 0.7328765392303467), ('crab', 0.7317043542861938), ('beetle', 0.7304386496543884), ('maple', 0.7257818579673767)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar('tree')) \n",
    "print(model.wv.most_similar('leaf')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationships\n",
    "\n",
    "Investigate the relationships between words in terms of trained representations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate  analogies\n",
    "With the model you have trained, evaluate the analogy\n",
    "`king-man+woman =~ queen`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.670697808265686), ('princess', 0.6247391700744629), ('empress', 0.6237273216247559), ('son', 0.6188290119171143), ('prince', 0.6153911352157593)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/trondlinjordet/anaconda3/envs/neural_ir/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print(model.most_similar(positive=['king', 'woman'], negative=['man'], topn=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the analogy `ship-boat+rocket =~ spacecraft`. How similar are the left-hand side of the analogy to the right-hand side? Implement a function that can find the answer for analogies in general. We assume the right-hand side of the analogy will always be a single, positive term. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_analogy(model, lhs_pos, lhs_neg, rhs):\n",
    "    \"\"\"Returns the similarity between the left-hand and right-hand sides of an anaology.\n",
    "    \n",
    "        Arguments: \n",
    "            model: Trained Gensim word2vec model to use.\n",
    "            lhs_pos: List of terms that are positive on the left-hand side in the analogy. \n",
    "            lhs_neg: List of terms that are negative on the left-hand side in the analogy. \n",
    "            rhs: A single positive term on the right-hand side in the analogy.\n",
    "            \n",
    "        Returns:\n",
    "            Float of the similarity if right-hand side term is found in the top 500 most similar terms.\n",
    "            Otherwise, return None.\"\"\"\n",
    "    # How similar are the left-hand side of the analogy to the right-hand side? \n",
    "    # Implement a function that can find the answer for analogies in general.\n",
    "    # TODO: Complete.\n",
    "    similarities_list = model.most_similar(positive=lhs_pos, negative=lhs_neg, topn=500)\n",
    "    similarities_dict = {}\n",
    "    for term, sim in similarities_list:\n",
    "        similarities_dict[term] = sim\n",
    "    if rhs in similarities_dict:\n",
    "        return similarities_dict[rhs]\n",
    "    else:\n",
    "        print(\"Right-hand side term not found in top 500 most similar terms to the left-hand side analogy.\")\n",
    "        None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F                                                                        [100%]\n",
      "=================================== FAILURES ===================================\n",
      "______________________________ test_eval_analogy _______________________________\n",
      "\n",
      "    def test_eval_analogy():\n",
      ">       assert eval_analogy(model, ['ship', 'rocket'], ['boat'], 'spacecraft') == pytest.approx(0.7043, abs=1e-4)\n",
      "E       AssertionError: assert 0.6901870369911194 == 0.7043 ± 1.0e-04\n",
      "E        +  where 0.6901870369911194 = eval_analogy(<gensim.models.word2vec.Word2Vec object at 0x117d44fd0>, ['ship', 'rocket'], ['boat'], 'spacecraft')\n",
      "E        +  and   0.7043 ± 1.0e-04 = <function approx at 0x117d3e0d0>(0.7043, abs=0.0001)\n",
      "E        +    where <function approx at 0x117d3e0d0> = pytest.approx\n",
      "\n",
      "<ipython-input-9-b916198ae617>:2: AssertionError\n",
      "=============================== warnings summary ===============================\n",
      "tmpclbytxa_.py::test_eval_analogy\n",
      "  /Users/trondlinjordet/anaconda3/envs/neural_ir/lib/python3.6/site-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "    app.launch_new_instance()\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/warnings.html\n",
      "=========================== short test summary info ============================\n",
      "FAILED tmpclbytxa_.py::test_eval_analogy - AssertionError: assert 0.690187036...\n",
      "1 failed, 1 warning in 0.22s\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "def test_eval_analogy():\n",
    "    assert eval_analogy(model, ['ship', 'rocket'], ['boat'], 'spacecraft') == pytest.approx(0.7043, abs=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-12 12:55:07,914 : INFO : loading projection weights from /Users/trondlinjordet/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n",
      "2020-10-12 12:55:59,462 : INFO : loaded (3000000, 300) matrix from /Users/trondlinjordet/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "model_loaded = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-12 12:55:59,469 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "loaded_analogy_eval = -1\n",
    "# Evaluate the analogy 'king'-'man'+'woman' compared to 'queen' using the loaded model \n",
    "# and assign the value to the variable `loaded_analogy_eval`.\n",
    "# TODO: Complete.\n",
    "loaded_analogy_eval = eval_analogy(model_loaded, ['king', 'woman'], ['man'], 'queen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".                                                                        [100%]\n",
      "1 passed in 0.01s\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "def test_loaded_analogy_eval():\n",
    "    assert loaded_analogy_eval != -1\n",
    "    assert loaded_analogy_eval == pytest.approx(0.7118, abs=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Word2Vec on different corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-10-12 12:56:14--  https://raw.githubusercontent.com/gsurma/text_predictor/master/data/kanye/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.64.133, 151.101.128.133, 151.101.192.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.64.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 330453 (323K) [text/plain]\n",
      "Saving to: ‘input.txt’\n",
      "\n",
      "input.txt           100%[===================>] 322,71K  --.-KB/s    in 0,1s    \n",
      "\n",
      "2020-10-12 12:56:18 (2,35 MB/s) - ‘input.txt’ saved [330453/330453]\n",
      "\n",
      "--2020-10-12 12:56:18--  https://raw.githubusercontent.com/gsurma/text_predictor/master/data/shakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.64.133, 151.101.128.133, 151.101.192.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.64.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4573338 (4,4M) [text/plain]\n",
      "Saving to: ‘input.txt’\n",
      "\n",
      "input.txt           100%[===================>]   4,36M  5,89MB/s    in 0,7s    \n",
      "\n",
      "2020-10-12 12:56:19 (5,89 MB/s) - ‘input.txt’ saved [4573338/4573338]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download the rap lyrics of Kanye West.\n",
    "! wget https://raw.githubusercontent.com/gsurma/text_predictor/master/data/kanye/input.txt\n",
    "! mv input.txt kanye.txt\n",
    "\n",
    "# Download the complete works of William Shakespeare.\n",
    "! wget https://raw.githubusercontent.com/gsurma/text_predictor/master/data/shakespeare/input.txt\n",
    "! mv input.txt shakespeare.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-12 12:56:19,821 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-10-12 12:56:19,823 : INFO : built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "\n",
    "class MyCorpus(object):\n",
    "    \"\"\"An interator that yields sentences (lists of str).\"\"\"\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __iter__(self):\n",
    "        corpus_path = datapath(self.data)\n",
    "        for line in open(corpus_path):\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield utils.simple_preprocess(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separately train two new models using the two different datasets, and compare how these datasets affect relationships between "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "kanye_data = MyCorpus(os.getcwd()+'/kanye.txt')\n",
    "shakespeare_data = MyCorpus(os.getcwd()+'/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-12 12:56:19,840 : INFO : collecting all words and their counts\n",
      "2020-10-12 12:56:19,842 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-10-12 12:56:19,962 : INFO : collected 5643 word types from a corpus of 58845 raw words and 9181 sentences\n",
      "2020-10-12 12:56:19,963 : INFO : Loading a fresh vocabulary\n",
      "2020-10-12 12:56:19,970 : INFO : effective_min_count=5 retains 1241 unique words (21% of original 5643, drops 4402)\n",
      "2020-10-12 12:56:19,972 : INFO : effective_min_count=5 leaves 52070 word corpus (88% of original 58845, drops 6775)\n",
      "2020-10-12 12:56:19,981 : INFO : deleting the raw counts dictionary of 5643 items\n",
      "2020-10-12 12:56:19,982 : INFO : sample=0.001 downsamples 69 most-common words\n",
      "2020-10-12 12:56:19,984 : INFO : downsampling leaves estimated 37293 word corpus (71.6% of prior 52070)\n",
      "2020-10-12 12:56:19,995 : INFO : estimated required memory for 1241 words and 100 dimensions: 1613300 bytes\n",
      "2020-10-12 12:56:19,997 : INFO : resetting layer weights\n",
      "2020-10-12 12:56:20,272 : INFO : training model with 3 workers on 1241 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-10-12 12:56:20,401 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-12 12:56:20,406 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-12 12:56:20,410 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-12 12:56:20,411 : INFO : EPOCH - 1 : training on 58845 raw words (37253 effective words) took 0.1s, 271704 effective words/s\n",
      "2020-10-12 12:56:20,555 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-12 12:56:20,557 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-12 12:56:20,562 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-12 12:56:20,563 : INFO : EPOCH - 2 : training on 58845 raw words (37215 effective words) took 0.1s, 256354 effective words/s\n",
      "2020-10-12 12:56:20,697 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-12 12:56:20,701 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-12 12:56:20,705 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-12 12:56:20,706 : INFO : EPOCH - 3 : training on 58845 raw words (37282 effective words) took 0.1s, 275094 effective words/s\n",
      "2020-10-12 12:56:20,837 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-12 12:56:20,839 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-12 12:56:20,844 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-12 12:56:20,846 : INFO : EPOCH - 4 : training on 58845 raw words (37377 effective words) took 0.1s, 284463 effective words/s\n",
      "2020-10-12 12:56:20,977 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-12 12:56:20,981 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-12 12:56:20,987 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-12 12:56:20,988 : INFO : EPOCH - 5 : training on 58845 raw words (37315 effective words) took 0.1s, 266054 effective words/s\n",
      "2020-10-12 12:56:20,989 : INFO : training on a 294225 raw words (186442 effective words) took 0.7s, 260333 effective words/s\n"
     ]
    }
   ],
   "source": [
    "kanye_model = None\n",
    "# Train a Word2Vec model on the Kanye corpus, and name it `kanye_model`.\n",
    "# TODO: Complete\n",
    "kanye_model = Word2Vec(sentences=kanye_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-12 13:00:26,405 : INFO : collecting all words and their counts\n",
      "2020-10-12 13:00:26,407 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-10-12 13:00:26,508 : INFO : PROGRESS: at sentence #10000, processed 46762 words, keeping 5336 word types\n",
      "2020-10-12 13:00:26,607 : INFO : PROGRESS: at sentence #20000, processed 99516 words, keeping 8036 word types\n",
      "2020-10-12 13:00:26,705 : INFO : PROGRESS: at sentence #30000, processed 150456 words, keeping 9920 word types\n",
      "2020-10-12 13:00:26,795 : INFO : PROGRESS: at sentence #40000, processed 195977 words, keeping 11442 word types\n",
      "2020-10-12 13:00:26,886 : INFO : PROGRESS: at sentence #50000, processed 242171 words, keeping 12738 word types\n",
      "2020-10-12 13:00:26,973 : INFO : PROGRESS: at sentence #60000, processed 285628 words, keeping 13827 word types\n",
      "2020-10-12 13:00:27,076 : INFO : PROGRESS: at sentence #70000, processed 331742 words, keeping 14731 word types\n",
      "2020-10-12 13:00:27,188 : INFO : PROGRESS: at sentence #80000, processed 383270 words, keeping 15682 word types\n",
      "2020-10-12 13:00:27,282 : INFO : PROGRESS: at sentence #90000, processed 430218 words, keeping 16435 word types\n",
      "2020-10-12 13:00:27,377 : INFO : PROGRESS: at sentence #100000, processed 477937 words, keeping 17391 word types\n",
      "2020-10-12 13:00:27,487 : INFO : PROGRESS: at sentence #110000, processed 524430 words, keeping 18393 word types\n",
      "2020-10-12 13:00:27,589 : INFO : PROGRESS: at sentence #120000, processed 569379 words, keeping 19095 word types\n",
      "2020-10-12 13:00:27,694 : INFO : PROGRESS: at sentence #130000, processed 617934 words, keeping 19995 word types\n",
      "2020-10-12 13:00:27,795 : INFO : PROGRESS: at sentence #140000, processed 668769 words, keeping 20960 word types\n",
      "2020-10-12 13:00:27,892 : INFO : PROGRESS: at sentence #150000, processed 716948 words, keeping 21612 word types\n",
      "2020-10-12 13:00:28,004 : INFO : PROGRESS: at sentence #160000, processed 766707 words, keeping 22174 word types\n",
      "2020-10-12 13:00:28,095 : INFO : collected 22555 word types from a corpus of 802937 raw words and 167204 sentences\n",
      "2020-10-12 13:00:28,096 : INFO : Loading a fresh vocabulary\n",
      "2020-10-12 13:00:28,121 : INFO : effective_min_count=5 retains 8117 unique words (35% of original 22555, drops 14438)\n",
      "2020-10-12 13:00:28,122 : INFO : effective_min_count=5 leaves 778092 word corpus (96% of original 802937, drops 24845)\n",
      "2020-10-12 13:00:28,152 : INFO : deleting the raw counts dictionary of 22555 items\n",
      "2020-10-12 13:00:28,154 : INFO : sample=0.001 downsamples 63 most-common words\n",
      "2020-10-12 13:00:28,156 : INFO : downsampling leaves estimated 595998 word corpus (76.6% of prior 778092)\n",
      "2020-10-12 13:00:28,186 : INFO : estimated required memory for 8117 words and 100 dimensions: 10552100 bytes\n",
      "2020-10-12 13:00:28,188 : INFO : resetting layer weights\n",
      "2020-10-12 13:00:29,968 : INFO : training model with 3 workers on 8117 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-10-12 13:00:31,003 : INFO : EPOCH 1 - PROGRESS: at 50.09% examples, 288742 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 13:00:31,967 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-12 13:00:31,973 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-12 13:00:31,980 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-12 13:00:31,981 : INFO : EPOCH - 1 : training on 802937 raw words (595951 effective words) took 2.0s, 296486 effective words/s\n",
      "2020-10-12 13:00:33,070 : INFO : EPOCH 2 - PROGRESS: at 50.09% examples, 274984 words/s, in_qsize 2, out_qsize 0\n",
      "2020-10-12 13:00:33,946 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-12 13:00:33,949 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-12 13:00:33,954 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-12 13:00:33,954 : INFO : EPOCH - 2 : training on 802937 raw words (595879 effective words) took 2.0s, 302604 effective words/s\n",
      "2020-10-12 13:00:35,234 : INFO : EPOCH 3 - PROGRESS: at 36.41% examples, 170451 words/s, in_qsize 4, out_qsize 0\n",
      "2020-10-12 13:00:36,239 : INFO : EPOCH 3 - PROGRESS: at 93.69% examples, 244789 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 13:00:36,323 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-12 13:00:36,328 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-12 13:00:36,333 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-12 13:00:36,333 : INFO : EPOCH - 3 : training on 802937 raw words (596252 effective words) took 2.4s, 251711 effective words/s\n",
      "2020-10-12 13:00:37,425 : INFO : EPOCH 4 - PROGRESS: at 47.59% examples, 262240 words/s, in_qsize 5, out_qsize 0\n",
      "2020-10-12 13:00:38,276 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-12 13:00:38,277 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-12 13:00:38,283 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-12 13:00:38,284 : INFO : EPOCH - 4 : training on 802937 raw words (596254 effective words) took 1.9s, 307365 effective words/s\n",
      "2020-10-12 13:00:39,295 : INFO : EPOCH 5 - PROGRESS: at 42.78% examples, 251375 words/s, in_qsize 6, out_qsize 0\n",
      "2020-10-12 13:00:40,222 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-12 13:00:40,224 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-12 13:00:40,226 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-12 13:00:40,227 : INFO : EPOCH - 5 : training on 802937 raw words (596149 effective words) took 1.9s, 307167 effective words/s\n",
      "2020-10-12 13:00:41,231 : INFO : EPOCH 6 - PROGRESS: at 46.21% examples, 274935 words/s, in_qsize 2, out_qsize 0\n",
      "2020-10-12 13:00:42,154 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-12 13:00:42,160 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-12 13:00:42,166 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-12 13:00:42,166 : INFO : EPOCH - 6 : training on 802937 raw words (595943 effective words) took 1.9s, 307599 effective words/s\n",
      "2020-10-12 13:00:43,215 : INFO : EPOCH 7 - PROGRESS: at 45.06% examples, 257381 words/s, in_qsize 5, out_qsize 0\n",
      "2020-10-12 13:00:44,092 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-12 13:00:44,094 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-12 13:00:44,098 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-12 13:00:44,098 : INFO : EPOCH - 7 : training on 802937 raw words (595869 effective words) took 1.9s, 309456 effective words/s\n",
      "2020-10-12 13:00:45,102 : INFO : EPOCH 8 - PROGRESS: at 41.46% examples, 245671 words/s, in_qsize 5, out_qsize 0\n",
      "2020-10-12 13:00:46,233 : INFO : EPOCH 8 - PROGRESS: at 79.29% examples, 219573 words/s, in_qsize 4, out_qsize 1\n",
      "2020-10-12 13:00:46,503 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-12 13:00:46,505 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-12 13:00:46,510 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-12 13:00:46,511 : INFO : EPOCH - 8 : training on 802937 raw words (596023 effective words) took 2.4s, 247262 effective words/s\n",
      "2020-10-12 13:00:47,519 : INFO : EPOCH 9 - PROGRESS: at 43.89% examples, 259614 words/s, in_qsize 3, out_qsize 0\n",
      "2020-10-12 13:00:48,470 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-12 13:00:48,472 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-12 13:00:48,478 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-12 13:00:48,479 : INFO : EPOCH - 9 : training on 802937 raw words (596165 effective words) took 2.0s, 303387 effective words/s\n",
      "2020-10-12 13:00:49,500 : INFO : EPOCH 10 - PROGRESS: at 47.41% examples, 278244 words/s, in_qsize 2, out_qsize 0\n",
      "2020-10-12 13:00:50,429 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-12 13:00:50,433 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-12 13:00:50,436 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-12 13:00:50,437 : INFO : EPOCH - 10 : training on 802937 raw words (596540 effective words) took 2.0s, 305042 effective words/s\n",
      "2020-10-12 13:00:50,438 : INFO : training on a 8029370 raw words (5961025 effective words) took 20.5s, 291235 effective words/s\n"
     ]
    }
   ],
   "source": [
    "shakespeare_model = None\n",
    "# Train a Word2Vec model on the Shakespeare corpus, and name it `shakespeare_model`.\n",
    "# TODO: Complete\n",
    "shakespeare_model = Word2Vec(sentences=shakespeare_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the models, we can easily find words where the two models learn very different similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/trondlinjordet/anaconda3/envs/neural_ir/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n",
      "2020-10-12 12:56:36,173 : INFO : precomputing L2-norms of word weight vectors\n",
      "/Users/trondlinjordet/anaconda3/envs/neural_ir/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "2020-10-12 12:56:36,177 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('yo', 0.9996579885482788), ('before', 0.9996414184570312), ('die', 0.999640703201294), ('his', 0.9996396899223328), ('away', 0.9996213912963867)]\n",
      "[('prince', 0.8854881525039673), ('duke', 0.7881519198417664), ('crown', 0.7170592546463013), ('devil', 0.6886593103408813), ('bolingbroke', 0.6861094236373901)]\n"
     ]
    }
   ],
   "source": [
    "# For example, compare:\n",
    "print(kanye_model.most_similar(positive=['king'], topn=5))\n",
    "print(shakespeare_model.most_similar(positive=['king'], topn=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Skip-gram and CBOW\n",
    "\n",
    "By using the arguments of the model (training) method in `gensim.models.Word2Vec()` you can select either Skip-gram or CBOW explicitly, as well as modifying other hyperparameters. \n",
    "\n",
    "Train a Skip-gram model on the Shakespeare corpus and compare with the default CBOW model on the same dataset, with the same context window size, and compare how relationships are expressed in terms of the resulting embedding vectors.\n",
    "\n",
    "**Hint:** Use the keyword argument `sg` in when instantiating the model object to specify Skip-gram, rather than the defaul CBOW setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-12 13:00:50,450 : INFO : collecting all words and their counts\n",
      "2020-10-12 13:00:50,452 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-10-12 13:00:50,561 : INFO : PROGRESS: at sentence #10000, processed 46762 words, keeping 5336 word types\n",
      "2020-10-12 13:00:50,667 : INFO : PROGRESS: at sentence #20000, processed 99516 words, keeping 8036 word types\n",
      "2020-10-12 13:00:50,778 : INFO : PROGRESS: at sentence #30000, processed 150456 words, keeping 9920 word types\n",
      "2020-10-12 13:00:50,871 : INFO : PROGRESS: at sentence #40000, processed 195977 words, keeping 11442 word types\n",
      "2020-10-12 13:00:50,963 : INFO : PROGRESS: at sentence #50000, processed 242171 words, keeping 12738 word types\n",
      "2020-10-12 13:00:51,054 : INFO : PROGRESS: at sentence #60000, processed 285628 words, keeping 13827 word types\n",
      "2020-10-12 13:00:51,152 : INFO : PROGRESS: at sentence #70000, processed 331742 words, keeping 14731 word types\n",
      "2020-10-12 13:00:51,253 : INFO : PROGRESS: at sentence #80000, processed 383270 words, keeping 15682 word types\n",
      "2020-10-12 13:00:51,346 : INFO : PROGRESS: at sentence #90000, processed 430218 words, keeping 16435 word types\n",
      "2020-10-12 13:00:51,449 : INFO : PROGRESS: at sentence #100000, processed 477937 words, keeping 17391 word types\n",
      "2020-10-12 13:00:51,550 : INFO : PROGRESS: at sentence #110000, processed 524430 words, keeping 18393 word types\n",
      "2020-10-12 13:00:51,641 : INFO : PROGRESS: at sentence #120000, processed 569379 words, keeping 19095 word types\n",
      "2020-10-12 13:00:51,741 : INFO : PROGRESS: at sentence #130000, processed 617934 words, keeping 19995 word types\n",
      "2020-10-12 13:00:51,841 : INFO : PROGRESS: at sentence #140000, processed 668769 words, keeping 20960 word types\n",
      "2020-10-12 13:00:51,935 : INFO : PROGRESS: at sentence #150000, processed 716948 words, keeping 21612 word types\n",
      "2020-10-12 13:00:52,035 : INFO : PROGRESS: at sentence #160000, processed 766707 words, keeping 22174 word types\n",
      "2020-10-12 13:00:52,107 : INFO : collected 22555 word types from a corpus of 802937 raw words and 167204 sentences\n",
      "2020-10-12 13:00:52,107 : INFO : Loading a fresh vocabulary\n",
      "2020-10-12 13:00:52,134 : INFO : effective_min_count=5 retains 8117 unique words (35% of original 22555, drops 14438)\n",
      "2020-10-12 13:00:52,135 : INFO : effective_min_count=5 leaves 778092 word corpus (96% of original 802937, drops 24845)\n",
      "2020-10-12 13:00:52,168 : INFO : deleting the raw counts dictionary of 22555 items\n",
      "2020-10-12 13:00:52,169 : INFO : sample=0.001 downsamples 63 most-common words\n",
      "2020-10-12 13:00:52,170 : INFO : downsampling leaves estimated 595998 word corpus (76.6% of prior 778092)\n",
      "2020-10-12 13:00:52,198 : INFO : estimated required memory for 8117 words and 100 dimensions: 10552100 bytes\n",
      "2020-10-12 13:00:52,199 : INFO : resetting layer weights\n",
      "2020-10-12 13:00:53,864 : INFO : training model with 3 workers on 8117 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-10-12 13:00:54,873 : INFO : EPOCH 1 - PROGRESS: at 46.21% examples, 273740 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 13:00:55,887 : INFO : EPOCH 1 - PROGRESS: at 96.07% examples, 282657 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 13:00:55,929 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-12 13:00:55,941 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-12 13:00:55,957 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-12 13:00:55,958 : INFO : EPOCH - 1 : training on 802937 raw words (595758 effective words) took 2.1s, 284734 effective words/s\n",
      "2020-10-12 13:00:57,001 : INFO : EPOCH 2 - PROGRESS: at 48.79% examples, 281030 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 13:00:58,005 : INFO : EPOCH 2 - PROGRESS: at 96.07% examples, 280209 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 13:00:58,051 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-12 13:00:58,063 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-12 13:00:58,080 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-12 13:00:58,081 : INFO : EPOCH - 2 : training on 802937 raw words (596275 effective words) took 2.1s, 281806 effective words/s\n",
      "2020-10-12 13:00:59,093 : INFO : EPOCH 3 - PROGRESS: at 41.67% examples, 243939 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 13:01:00,094 : INFO : EPOCH 3 - PROGRESS: at 87.45% examples, 258296 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 13:01:00,312 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-12 13:01:00,322 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-12 13:01:00,342 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-12 13:01:00,342 : INFO : EPOCH - 3 : training on 802937 raw words (596270 effective words) took 2.3s, 263913 effective words/s\n",
      "2020-10-12 13:01:01,366 : INFO : EPOCH 4 - PROGRESS: at 50.09% examples, 293240 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 13:01:02,391 : INFO : EPOCH 4 - PROGRESS: at 98.53% examples, 287191 words/s, in_qsize 2, out_qsize 1\n",
      "2020-10-12 13:01:02,392 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-12 13:01:02,401 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-12 13:01:02,423 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-12 13:01:02,423 : INFO : EPOCH - 4 : training on 802937 raw words (596109 effective words) took 2.1s, 287396 effective words/s\n",
      "2020-10-12 13:01:03,449 : INFO : EPOCH 5 - PROGRESS: at 24.43% examples, 145466 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 13:01:04,458 : INFO : EPOCH 5 - PROGRESS: at 62.60% examples, 183026 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 13:01:05,347 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-12 13:01:05,357 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-12 13:01:05,376 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-12 13:01:05,377 : INFO : EPOCH - 5 : training on 802937 raw words (595806 effective words) took 3.0s, 201826 effective words/s\n",
      "2020-10-12 13:01:06,393 : INFO : EPOCH 6 - PROGRESS: at 42.78% examples, 250544 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 13:01:07,407 : INFO : EPOCH 6 - PROGRESS: at 90.06% examples, 263538 words/s, in_qsize 0, out_qsize 1\n",
      "2020-10-12 13:01:07,564 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-12 13:01:07,577 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-12 13:01:07,599 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-12 13:01:07,600 : INFO : EPOCH - 6 : training on 802937 raw words (596090 effective words) took 2.2s, 268550 effective words/s\n",
      "2020-10-12 13:01:08,634 : INFO : EPOCH 7 - PROGRESS: at 42.78% examples, 245984 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 13:01:09,655 : INFO : EPOCH 7 - PROGRESS: at 91.26% examples, 264237 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 13:01:09,818 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-12 13:01:09,825 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-12 13:01:09,844 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-12 13:01:09,845 : INFO : EPOCH - 7 : training on 802937 raw words (596459 effective words) took 2.2s, 266078 effective words/s\n",
      "2020-10-12 13:01:10,873 : INFO : EPOCH 8 - PROGRESS: at 47.41% examples, 276531 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 13:01:11,898 : INFO : EPOCH 8 - PROGRESS: at 97.41% examples, 282304 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 13:01:11,921 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-12 13:01:11,931 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-12 13:01:11,951 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-12 13:01:11,952 : INFO : EPOCH - 8 : training on 802937 raw words (596101 effective words) took 2.1s, 283330 effective words/s\n",
      "2020-10-12 13:01:12,959 : INFO : EPOCH 9 - PROGRESS: at 46.21% examples, 274986 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 13:01:13,967 : INFO : EPOCH 9 - PROGRESS: at 94.85% examples, 280448 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-12 13:01:14,026 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-12 13:01:14,037 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-12 13:01:14,054 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-12 13:01:14,055 : INFO : EPOCH - 9 : training on 802937 raw words (596332 effective words) took 2.1s, 283936 effective words/s\n",
      "2020-10-12 13:01:15,061 : INFO : EPOCH 10 - PROGRESS: at 37.76% examples, 222816 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 13:01:16,069 : INFO : EPOCH 10 - PROGRESS: at 79.29% examples, 232730 words/s, in_qsize 0, out_qsize 0\n",
      "2020-10-12 13:01:16,541 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-12 13:01:16,551 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-12 13:01:16,575 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-12 13:01:16,577 : INFO : EPOCH - 10 : training on 802937 raw words (595956 effective words) took 2.5s, 236591 effective words/s\n",
      "2020-10-12 13:01:16,579 : INFO : training on a 8029370 raw words (5961156 effective words) took 22.7s, 262448 effective words/s\n"
     ]
    }
   ],
   "source": [
    "shakespeare_model_sg = None\n",
    "# Train a Word2Vec model on the Shakespeare corpus, and name it `shakespeare_model`.\n",
    "# TODO: Complete\n",
    "shakespeare_model_sg = Word2Vec(sentences=shakespeare_data, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/trondlinjordet/anaconda3/envs/neural_ir/lib/python3.6/site-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  app.launch_new_instance()\n",
      "2020-10-12 13:01:22,120 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right-hand side term not found in top 500 most similar terms to the left-hand side analogy.\n"
     ]
    }
   ],
   "source": [
    "loaded_analogy_eval_sm_sg = eval_analogy(shakespeare_model_sg, ['king', 'woman'], ['man'], 'queen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/trondlinjordet/anaconda3/envs/neural_ir/lib/python3.6/site-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  app.launch_new_instance()\n",
      "2020-10-12 13:01:22,545 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "loaded_analogy_eval_sm_cbow = eval_analogy(shakespeare_model, ['king', 'woman'], ['man'], 'queen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F                                                                        [100%]\n",
      "=================================== FAILURES ===================================\n",
      "___________________________ test_loaded_analogy_eval ___________________________\n",
      "\n",
      "    def test_loaded_analogy_eval():\n",
      ">       assert loaded_analogy_eval_sm_cbow == None\n",
      "E       assert 0.48434120416641235 == None\n",
      "\n",
      "<ipython-input-28-39e50d74f192>:2: AssertionError\n",
      "=========================== short test summary info ============================\n",
      "FAILED tmp9hj30bki.py::test_loaded_analogy_eval - assert 0.48434120416641235 ...\n",
      "1 failed in 0.03s\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "def test_loaded_analogy_eval():\n",
    "    assert loaded_analogy_eval_sm_cbow == None\n",
    "    assert loaded_analogy_eval_sm_sg == pytest.approx(0.4652, abs=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information about Gensim, see https://radimrehurek.com/gensim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback\n",
    "\n",
    "Please give (anonymous) feedback on this exercise by filling out [this form](https://forms.gle/2jPayczbFhEcC9K68)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
